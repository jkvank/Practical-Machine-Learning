#~~~~~~~~~~~~~~~~~~~ Quiz 2 - Question 2 ~~~~~~~~~~~~~~~~~~~

library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[inTrain, ]
testing = mixtures[-inTrain, ]

summary(training)  # view summary of training data

dim(training);dim(testing)

featurePlot(x=training[,1:8],y=training$CompressiveStrength,plot="pairs")

index=seq(1,nrow(training))

qplot(index,training$CompressiveStrength,data=training)  # clearly shows steps

qplot(index,training$CompressiveStrength,colour=Age,data=training)  #no clear definition
qplot(index,training$CompressiveStrength,colour=FlyAsh,data=training) #no clear definition

#~~~~~~~~~~~~~~~~~~~ Quiz 2 - Question 3 ~~~~~~~~~~~~~~~~~~~

library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(training$Superplasticizer,data=training,geom="histogram") # histogram shows approx 300 samples  with Superplasticizer = 0

qplot(log(training$Superplasticizer+1),data=training,geom="histogram") # still shows skewed histogram

#~~~~~~~~~~~~~~~~~~~ Quiz 2 - Question 4 ~~~~~~~~~~~~~~~~~~~

library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]

IL_columns <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_columns], method = "pca", thresh = 0.8)
preProc$numComp # displays 7, or just use preProc
preProc    # outputs PCA needed 7 components to capture 80 percent of the variance

#~~~~~~~~~~~~~~~~~~~ Quiz 2 - Question 5 ~~~~~~~~~~~~~~~~~~~

library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]

IL_columns <- grep("^IL", colnames(training), value = TRUE)

# create a dataset with only columns beginniing with IL and diagnosis
# from http://www.r-tutor.com/r-introduction/data-frame/data-frame-column-slice

newtrainingset = training[c("diagnosis",IL_columns)]

# from the lecture Preprocessing with principal components analysis:
# preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
# trainPC <- predict(preProc,log10(training[,-58]+1))
# modelFit <- train(training$type ~ .,method="glm",data=trainPC)


# model using predictors from "newtrainingset" and no preprocessing  - meant to get 0.65 accuracy
modelFit1 <- train(diagnosis ~ .,method="glm",data=newtrainingset)

confusionMatrix(newtrainingset$diagnosis,predict(modelFit1, newtrainingset))

# model using predictors from "newtrainingset" and preprocessing using PCA - meant to get 0.72 accuracy
preProc <- preProcess(training[, IL_columns], method = "pca", thresh = 0.8)
trainPC <- predict(preProc,diagnosis)
modelFit2 <- train(diagnosis ~ .,method="glm",preProcess="pca",data=newtrainingset)


train(diagnosis ~ .,method="glm",preProcess="pca",data=newtrainingset)

#~~~~~~~~~~~~~~~~~~~ Quiz 3 - Question 1 ~~~~~~~~~~~~~~~~~~~

library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)

sO = segmentationOriginal
training = subset(sO, Case == "Train")
testing = subset(sO, Case == "Test")

set.seed(125)
dim(training);dim(testing)

modFit <- train(Class ~ .,method="rpart",data=training)
# plot(modFit$finalModel, uniform=TRUE,main="Classification Tree")
# text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)

library(rattle)
fancyRpartPlot(modFit$finalModel)

# make an array of sample data
pedictData = training[1,]
pedictData[1,names(pedictData)] = rep(NA, length(names(pedictData)))
pedictData = rbind(pedictData, pedictData)
pedictData = rbind(pedictData, pedictData)

keep = c('Case', 'Class', 'Cell')
#keep = c()
pedictData = training[1:4,]
pedictData[1,!(names(pedictData) %in% keep)] = rep(NA, length(names(pedictData))-length(keep))
pedictData[1, c('TotalIntenCh2', 'FiberWidthCh1', 'PerimStatusCh1')] = c(23000, 10, 2)
pedictData[2, c('TotalIntenCh2', 'FiberWidthCh1', 'VarIntenCh4')] = c(50000, 10, 100)
pedictData[3, c('TotalIntenCh2', 'FiberWidthCh1', 'VarIntenCh4')] = c(57000, 8, 100)
pedictData[4, c('FiberWidthCh1', 'VarIntenCh4', 'PerimStatusCh1')] = c(8, 100, 2)

predict(modFit, pedictData[1,])  # returns unknown
predict(modFit, pedictData[2,])  # returns WS
predict(modFit, pedictData[3,])  # returns PS
predict(modFit, pedictData[4,])  # returns PS

#~~~~~~~~~~~~~~~~~~~ Quiz 3 - Question 2 ~~~~~~~~~~~~~~~~~~~

# For k-Fold validation:  see Cross Validation vide lecture
# Larger K = less bias, more variance
# Smaller K = more bias, less variance
# Leave-One-Out cross validation - special case of k-Fold where k = N

#~~~~~~~~~~~~~~~~~~~ Quiz 3 - Question 3 ~~~~~~~~~~~~~~~~~~~

library(pgmm)
data(olive)
olive = olive[,-1]
modFit = train(Area ~ ., method = 'rpart', data = olive)
library(rattle)
fancyRpartPlot(modFit$finalModel)

newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata)

# The prediction returns a number instead of a catagory as the result
# Looking at: https://stat.ethz.ch/R-manual/R-devel/library/rpart/html/predict.rpart.html
#  - should we have used predict(modFit, newdata, type = "class") ? 

#~~~~~~~~~~~~~~~~~~~ Quiz 3 - Question 4 ~~~~~~~~~~~~~~~~~~~

library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
library(caret)
modFit = train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = 'glm', family = 'binomial', data = trainSA)
trainPred = predict(modFit, trainSA)
testPred = predict(modFit , testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
trainMissClass = missClass(trainSA$chd, trainPred)
testMissClass = missClass(testSA$chd, testPred)

#result is: trainMissClass  = 0.27 testMissClass  = 0.31

#~~~~~~~~~~~~~~~~~~~ Quiz 3 - Question 5 ~~~~~~~~~~~~~~~~~~~

library(ElemStatLearn)
data(vowel.train)
data(vowel.test) 

vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
modFit = train(y ~ ., method = 'rf', data = vowel.train, prox = TRUE)
varImp(model$finalModel)


